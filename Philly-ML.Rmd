---
title: "Philly-ML"
author: "Emily Zhou"
date: "2023-10-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data and Library

```{r libraries}


# list of required packages
packages <- c( "tidyverse", "ggplot2", "svDialogs", "tidycensus", "sf", "knitr", "rmarkdown", "kableExtra", "stringr", "spdep", "sfdep", "caret", "car", "ckanr", "FNN", "grid", "gridExtra", "ggcorrplot", "corrr", "jtools", "ggstance", "ggpubr", "broom.mixed", "stargazer", "gtsummary", "patchwork")

# install and load required packages
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE, quietly=TRUE)
      library(x, character.only = TRUE)
    }
  }
)

# global options 
options(scipen=999)
options(tigris_class = "sf")
options(digits = 3)

palette5 <- c("#ffffcc","#a1dab4","#41b6c4","#2c7fb8","#253494")

# load in multiple ring buffer function
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")


```


```{r data}

training <- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/studentData.geojson") %>% st_transform('ESRI:102728')
# training <- data %>% filter(toPredict != "CHALLENGE") %>% st_transform('ESRI:102728')

crime <- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/crime.geojson") %>% st_transform('ESRI:102728')

hospital <- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/Hospitals.geojson") %>% st_transform('ESRI:102728')

el <- st_read("https://opendata.arcgis.com/datasets/8c6e2575c8ad46eb887e6bb35825e1a6_0.geojson")
Broad_St <- st_read("https://opendata.arcgis.com/datasets/2e9037fd5bef406488ffe5bb67d21312_0.geojson")

schools <- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/school.geojson") %>% st_transform('ESRI:102728')

shopping <- st_read("https://services.arcgis.com/fLeGjb7u4uXqeF9q/arcgis/rest/services/Commercial_Corridors/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson") %>% st_transform('ESRI:102728') 

dst<- st_read("https://opendata.arcgis.com/datasets/0960ea0f38f44146bb562f2b212075aa_0.geojson")%>%
  st_transform('ESRI:102728') 
```

Report Outline 

- What variables in this data set that might be related to sale price? 
- What additional variables might be related to sale price? 
- Let's look at variables from the provided data set that we will use to fit a baseline regression first. Among which of these variables have we selected to put into regression, considering that some of these variables will be inherently related, and some of them will require additional manipulations, some of them needs to be included/excluded, etc. do data manipulations and processing
- 

- Summary table for all of the numeric variables
- Summary table for all of the categorical variables 
- scatterplot for numeric variables, do cor test
- histograms for categorical variables, do anova test

# Pre-Process


Briefly describe your methods for gathering the data (only baseline regression data) and selecting variables 
Present a table of summary statistics with variable descriptions. Sort these variables by their category (internal characteristics, amenities/public services or spatial structure). Check out the `stargazer` package for this.

Present a correlation matrix for only numeric variables (later)

4 home price correlation scatterplots

Develop 1 map of your dependent variable (sale price)
Develop 3 maps of 3 of your most interesting independent variables. (save maps for later analysis)

```{r variables checking}

anova_result <- aov(tr_processed$sale_price ~ as.factor(tr_processed$basements))
summary(anova_result)


tr_neigh %>% 
  ggplot(aes(x = basements)) +
  geom_bar() +
  labs(title = "Histogram Example", x = "X-Axis Label", y = "Frequency")

```


```{r process predictors}

tr_processed <- training %>% 
  mutate(Age = 2023 - year_built) %>% 
  mutate(numRooms = case_when(
         is.na(number_of_bedrooms) & !is.na(number_of_bedrooms) ~ number_of_bathrooms,
         is.na(number_of_bathrooms) & !is.na(number_of_bedrooms) ~ number_of_bedrooms,
         is.na(number_of_bathrooms) & is.na(number_of_bedrooms) ~ 0,
         TRUE~ number_of_bedrooms + number_of_bathrooms) )%>% 
  mutate(hasAC = case_when(
         central_air %in% c("1", "Y") ~ "Y",
         TRUE~ "N"),
         hasBasement = case_when(
         basements %in% c("1", "4", "A", "B", "C", "D", "E", "F") ~ "Y",
         TRUE~ "N"),
         hasFireplace = case_when(
         fireplaces == 0 | is.na(fireplaces)  ~ "N",
         TRUE~ "Y"),
         hasGarage = case_when(
         garage_type == 0 | is.na(garage_type)  ~ "N",
         TRUE~ "Y"),
         stories = case_when(
         number_stories == 1  ~ "single",
         number_stories == 2  ~ "double",
         TRUE~ "multiple"),
         area = case_when(
           total_livable_area > total_area ~ total_livable_area,  
           TRUE ~ total_area),
         hasHeater = case_when(
         type_heater == 0 | is.na(type_heater)  ~ "N",
         TRUE~ "Y"),
         view = case_when(
         view_type == "I" | view_type == "0" | is.na(view_type)   ~ "Typical",
         view_type == "A" | view_type == "B" | view_type == "C" ~ "Scenic",
         TRUE~ "Urban"), 
         quality = case_when(
         quality_grade %in% c("4", "5", "6", "A", "A+", "A-", "B", "B+","B-","S","S+","X-")  ~ "Good",
         TRUE~ "Bad"),
         buildingdis = case_when(
         grepl("ROW",building_code_description_new, ignore.case = FALSE) ~ "Row",
         grepl("TWIN",building_code_description_new, ignore.case = FALSE) ~ "TWIN",
         TRUE~ "Other")) %>% 
  mutate(logarea = log(area))

  

```



# Baseline Regression

```{r}
baseline <- tr_processed %>% 
  filter(toPredict != "CHALLENGE") %>%
  filter(Age < 500) %>% 
  filter(sale_price < 2000000) %>% 
  filter(numRooms < 30) %>% 
  filter(total_livable_area != 0 & is.na(total_area) == FALSE) %>% 
  filter(area < 50000) 
```


```{r base regression}

reg1 <- lm(sale_price ~ ., data = baseline %>% st_drop_geometry() %>% 
                                 dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                               hasFireplace, hasGarage, stories, logarea, view))

summary(reg1)
```



```{r check base regression colinearity}
vif(reg1)
```



```{r residual plot baseline}
residuals_df <- data.frame(Residuals = resid(reg1), Fitted = fitted(reg1))
ggplot(residuals_df, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residual Plot")
```


```{r generalizability baseline}

set.seed(485) 
inTrain_base <- createDataPartition(
   y = paste(baseline$hasBasement, baseline$hasAC, baseline$quality, baseline$buildingdis, baseline$hasFireplace, baseline$hasGarage, baseline$stories, baseline$view),
              p = .60, list = FALSE)

tr_processed.training <- baseline[inTrain_base,] 
tr_processed.test <- baseline[-inTrain_base,]  


reg.train_base <- lm(sale_price ~ ., data = tr_processed.training %>% st_drop_geometry() %>% 
                                 dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                               hasFireplace, hasGarage, stories, logarea, view))
tr_processed.test <- 
  tr_processed.test %>% 
  mutate(Regression = "Base", 
         SalePrice.Predict = predict(reg.train_base, tr_processed.test),
         SalePrice.Error = SalePrice.Predict - sale_price,
         SalePrice.AbsError = abs(SalePrice.Predict - sale_price),
         SalePrice.APE = (abs(SalePrice.Predict - sale_price)) / SalePrice.Predict)
```


```{r basline MAPE}

mean(tr_processed.test$SalePrice.APE, na.rm = T)

```

# Check Spatial Auto Correlation

```{r Global G test}

coords.test <-  st_coordinates(tr_processed.test) 
neighborList.test <- knn2nb(knearneigh(coords.test, 5))
spatialWeights.test <- nb2listw(neighborList.test, style="W")
```

```{r Global Moran I}
moranTest <- moran.mc(tr_processed.test$SalePrice.Error, 
                      spatialWeights.test, nsim = 999)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()

```



```{r block group and sale price}

block <- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/Census_Blocks_2010.geojson") %>% st_transform('ESRI:102728')

tr_block <- st_join(tr_processed, block %>% select(GEOID10))

gi_data <- tr_block %>% 
  st_drop_geometry() %>% 
  select(GEOID10, sale_price) %>% 
  group_by(GEOID10) %>% 
  summarize(mean_sp = mean(sale_price)) %>% 
  na.omit() %>% 
  left_join(block) %>% 
  st_sf()

gi_data <- gi_data %>% 
  st_make_valid()

```


```{r Getid Ord local G statistics}

list_nb <- poly2nb(gi_data, queen = TRUE)

empty_nb <- which(card(list_nb) == 0)
   
gi_subset <- gi_data[-empty_nb, ]

neigh_nbs <- gi_subset %>% 
  mutate(
    nb = st_contiguity(geometry),        # neighbors share border/vertex
    wt = st_weights(nb),                 # row-standardized weights
    neigh_lag = st_lag(mean_sp, nb, wt)    # calculate spatial lag of TreEqty
  )

gi_hot_spots <- neigh_nbs %>% 
  mutate(
    Gi = local_g_perm(mean_sp, nb, wt, nsim = 999)
    # nsim = number of Monte Carlo simulations (999 is default)
  ) %>% 
  unnest(Gi) 

gi_hot_spots %>% 
  ggplot((aes(fill = gi))) +
  geom_sf(color = NA) +
scale_fill_gradient2() + theme_void()
```

# Neighborhood Effect


```{r bring in neighborhood}

tr_neigh <- st_intersection(tr_processed, dst %>% dplyr::select("DIST_NAME"))


```



```{r bring in assult}
assault <- crime %>% 
  filter(text_gener == "Aggravated Assault Firearm" | text_gener == "Aggravated Assault No Firearm") %>% 
  dplyr::select(point_x, point_y) %>%
  na.omit() %>% 
  st_as_sf(coords = c("Long", "Lat"), crs = "EPSG:102728") %>%
  distinct()

tr_neigh$crimes.Buffer <- tr_neigh %>% 
    st_buffer(660) %>% 
    aggregate(mutate(assault, counter = 1),., sum) %>%
    pull(counter) 
  tr_neigh$crimes.Buffer[is.na(tr_neigh$crimes.Buffer)] <- 0

```



```{r bring in school}
schools <- schools %>% 
  filter(GRADE_ORG == "K-12" | GRADE_ORG == "9-12") %>%  
  filter(TYPE_SPECIFIC == "PRIVATE") 

school_buffer <-
  schools %>%
  dplyr::select(geometry) %>%
  st_transform('ESRI:102728') %>%
    na.omit() 

tr_neigh$school_buffer <- 
    tr_neigh$geometry %>% 
    st_buffer(5280) %>% 
    aggregate(mutate(school_buffer, counter = 1),., sum) %>%
    pull(counter)

tr_neigh$school_buffer[is.na(tr_neigh$school_buffer)] <- 0

```


```{r bring in hospital}

tr_neigh <-
  tr_neigh %>% 
    mutate(hospitals_nn1 = nn_function(st_coordinates(tr_neigh), 
                              st_coordinates(hospital), k = 1))
```


```{r bring in shops}

shops <- st_centroid(shopping) %>% dplyr::select("OBJECTID", "geometry")

tr_neigh <-
  tr_neigh %>% 
    mutate(shops_nn3 = nn_function(st_coordinates(tr_neigh), 
                              st_coordinates(shops), k = 3))
```



```{r bring in transit stations}


septaStops <- 
  rbind(
     el %>% 
      mutate(Line = "El") %>%
      dplyr::select(Station, Line),
     Broad_St %>%
      mutate(Line ="Broad_St") %>%
      dplyr::select(Station, Line)) %>%
  st_transform('ESRI:102728')
  

joinstops <- tr_neigh %>% 
  st_intersection(st_buffer(septaStops, 3000)) %>% 
  st_drop_geometry() %>% 
  group_by(parcel_number) %>% 
  summarize(
    totalstops = n())

tr_neigh <- tr_neigh %>% 
  left_join(joinstops, by = "parcel_number") 
  
tr_neigh <- tr_neigh %>% 
  mutate(totalstops = ifelse(is.na(totalstops), 0, totalstops))
  
```


```{r bring in race}

census_api_key(dlgInput(
  "Enter a Census API Key", # ask for an api key
  Sys.getenv("CENSUS_API_KEY")
)$res,
overwrite = TRUE)


tracts20 <- 
  get_acs(geography = "tract", 
          variables = c("B02001_001E", # total population
            "B02001_002E", # white population
            "B02001_003E", # black population
            "B02001_005E", # asian population
            "B03002_012E"), 
          year=2020, state=42, county=101, 
          geometry=TRUE, output="wide") %>%
  st_transform('ESRI:102728') %>% 
  rename(TotalPop = B02001_001E, 
         Whites = B02001_002E,
         African_Americans = B02001_003E,
         Asians = B02001_005E,
         Latinx = B03002_012E) %>% 
  mutate(pctMinority = ifelse(TotalPop > 0, (African_Americans + Asians + Latinx ) / TotalPop, 0), 
         majority = ifelse(pctMinority > 0.5, "minority", "majority"))
  
```


```{r}

joinrace <- tr_neigh %>% 
  st_intersection(tracts20 %>% select(pctMinority)) %>% 
  st_drop_geometry() %>% 
  group_by(parcel_number) %>% 
  summarize(
    meanMinor = mean(pctMinority))

tr_neigh <- tr_neigh %>% 
  left_join(joinrace, by = "parcel_number") 
```

```{r}

neighboreffect <- tr_neigh %>% 
  filter(toPredict != "CHALLENGE") %>%
  filter(Age < 500 & Age > -1) %>% 
  filter(sale_price < 2000000) %>% 
  filter(numRooms < 30) %>% 
  filter(total_livable_area != 0 & is.na(total_area) == FALSE) %>% 
  filter(area < 50000) 
  
```



```{r neighborhood regression}
reg2 <- lm(sale_price ~ ., data = neighboreffect %>% st_drop_geometry() %>% 
                                 dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                               hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor))
summary(reg2)
```


```{r check neighborhood regression colinearity}
vif(reg2)
```



```{r generalizability neighborhood}


set.seed(485) 

inTrain <- createDataPartition(
    y = paste(neighboreffect$DIST_NAME, neighboreffect$hasBasement, neighboreffect$hasAC, neighboreffect$quality, neighboreffect$buildingdis, neighboreffect$hasFireplace, neighboreffect$hasGarage, neighboreffect$stories, neighboreffect$view), 
             p = .60, list = FALSE)


tr_neigh.training <- neighboreffect[inTrain,] 
tr_neigh.test <- neighboreffect[-inTrain,]  

reg.train <- lm(sale_price ~ ., data = tr_neigh.training %>% st_drop_geometry() %>% 
                                 dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                               hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor))


tr_neigh.test <- 
  tr_neigh.test %>% 
  mutate(Regression = "Neighborhood Effects", 
    SalePrice.Predict = predict(reg.train, tr_neigh.test),
         SalePrice.Error = SalePrice.Predict - sale_price,
         SalePrice.AbsError = abs(SalePrice.Predict - sale_price),
         SalePrice.APE = (abs(SalePrice.Predict - sale_price)) / SalePrice.Predict)

```


```{r}
tr_neigh.test %>% 
  st_drop_geometry() %>%
  summarise(MAE = mean(SalePrice.AbsError),
            MAPE = mean(SalePrice.APE)*100) %>%
  kbl(col.name=c('Mean Absolute Error','Mean Absolute Percentage Error')) %>%
  kable_styling()
```





```{r cross validation}

fitControl <- trainControl(method = "cv", number = 100)
set.seed(485)

reg.cv <- 
  train(sale_price ~ ., data = st_drop_geometry(neighboreffect) %>% 
                             dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                               hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor), method = "lm", trControl = fitControl, na.action = na.pass)

reg.cv
```


```{r}
reg.cv$resample %>% 
  summarise(MAE = mean(reg.cv$resample[,3]),
            sd(reg.cv$resample[,3])
) %>%
  kbl(col.name=c('Mean Absolute Error','Mean Absolute Percentage Error')) %>%
  kable_styling()
```



```{r}
reg.cv$resample %>% 
ggplot(aes(x=reg.cv$resample[,3])) +
    geom_histogram( fill="#69b3a2", color="#e9ecef", alpha=0.9) 
```


```{r}
set.seed(311)
challenge <- tr_neigh %>% 
  filter(toPredict == "CHALLENGE")

PricePrediction <-
  st_drop_geometry(challenge)%>%
  mutate(prediction = predict(reg.train, challenge))%>%
  dplyr::select(musaID, prediction)
  
# write.csv(PricePrediction,"RegressToImpress.csv", row.names = FALSE)
```


```{r}
tr_neigh.test %>%
  dplyr::select(SalePrice.Predict, sale_price) %>%
  ggplot(aes(sale_price, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(sale_price, sale_price), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  stat_smooth(aes(SalePrice.Predict, sale_price), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  labs(title="Predicted sale price as a function of observed price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction")
```

```{r}

coords.test_n <-  st_coordinates(tr_neigh.test) 
neighborList.test_n <- knn2nb(knearneigh(coords.test_n, 5))
spatialWeights.test_n <- nb2listw(neighborList.test_n, style="W")

tr_neigh.test %>% 
  mutate(lagPriceError = lag.listw(spatialWeights.test_n, SalePrice.Error)) %>%
  ggplot()+
  geom_point(aes(x =lagPriceError, y =SalePrice.Error))+
  stat_smooth(aes(lagPriceError, SalePrice.Error), 
             method = "lm", se = FALSE, size = 1, colour="blue")  
```


```{r}

moranTest_n <- moran.mc(tr_neigh.test$SalePrice.Error, 
                      spatialWeights.test_n, nsim = 999)

ggplot(as.data.frame(moranTest_n$res[c(1:999)]), aes(moranTest_n$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest_n$statistic), colour = "orange",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") 
```





```{r}

neighboreffect_nongeom <- neighboreffect %>% st_drop_geometry()
neighboreffect_nongeom  <- neighboreffect_nongeom  %>%
  dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor) %>% 
    dplyr::select_if(is.numeric)

stargazer(neighboreffect_nongeom, type = 'text', title= "Table 1: Summary Statistics")

```


```{r}
varibles <- 
  neighboreffect %>% 
  dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor)

vars <- select_if(st_drop_geometry(varibles), is.numeric) %>% na.omit()

ggcorrplot(
  round(cor(vars), 1), 
  p.mat = cor_pmat(vars),
  colors = c("#5F9EA0", "white", "#ff6347"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation") 
```




```{r}

vars <- select_if(st_drop_geometry(varibles), negate(is.numeric)) %>% na.omit()
vars %>% tbl_summary() %>% as_kable() %>%  kable_styling()

```



```{r anova numeric varible}
anova_var <- c("DIST_NAME", "view", "stories", "hasGarage", "hasFireplace", "buildingdis", "quality", "hasAC", "hasBasement")

anova_summary_table <- data.frame(Df = integer(0), Sum_Sq = numeric(0), Mean_Sq = numeric(0), F_value = numeric(0))
row_names <- character(0)

for (i in seq_along(anova_var)) {
  var <- anova_var[i]
  anova_result <- aov(neighboreffect$sale_price ~ as.factor(neighboreffect[[var]]))
  #paste("ANOVA result for", var)
  summary_data <- summary(anova_result)[[1]][, c("Df", "Sum Sq", "Mean Sq", "F value")]
  anova_summary_table <- rbind(anova_summary_table, summary_data)
   row_names <- c(row_names, paste(var))
}

filter_condition <- !grepl("Residuals", rownames(anova_summary_table))
filtered_anova_summary <- anova_summary_table[filter_condition, ]

rownames(filtered_anova_summary) <- row_names
kable(filtered_anova_summary) %>% kable_styling()
```



```{r correlation categorical varible}
cor_var <- c("Age", "numRooms", "logarea", "crimes.Buffer", "totalstops", "hospitals_nn1", "shops_nn3", "school_buffer", "meanMinor")

cor_summary_table <- data.frame(Variable = character(0), Correlation = numeric(0))

for (var in cor_var) {
  correlation_test <- cor.test(neighboreffect$sale_price, neighboreffect[[var]])
  correlation <- correlation_test$estimate
  p_value <- correlation_test$p.value
  t_statistic <- correlation_test$statistic 
  ci_lower <- correlation_test$conf.int[1] 
  ci_upper <- correlation_test$conf.int[2] 
  summary_data <- data.frame(Variable = var, Correlation = correlation, P_Value = p_value, T_Statistic = t_statistic, CI_Lower = ci_lower, CI_Upper = ci_upper)
  cor_summary_table <- rbind(cor_summary_table, summary_data)
}

cor_summary_table$P_Value <- sprintf("%.3f", cor_summary_table$P_Value)

cor_summary_table$P_Value <- ifelse(cor_summary_table$P_Value < 0.001, paste0("< 0.001", "***"), ifelse(cor_summary_table$P_Value < 0.01, paste0(cor_summary_table$P_Value, "**"), ifelse(cor_summary_table$P_Value < 0.05, paste0(cor_summary_table$P_Value, "*"), as.character(cor_summary_table$P_Value))))

kable(cor_summary_table, row.names = FALSE) %>% kable_styling()

```



```{r}
export_summs(reg1, reg2)
```


```{r}
neighboreffect_nongeom_long <- neighboreffect_nongeom%>% 
  pivot_longer(cols = -sale_price, # everything except measurement
               names_to = "Type", # categorizes all quantitative variables into Type
               values_to = "Number") # the name of values is Number


scatterplot <- neighboreffect_nongeom_long %>%
  ggplot(aes(x= Number, y = sale_price)) +
  geom_point(size = 0.01) +  # smaller the size of each point
      geom_smooth(method='lm', formula= y~x) +
  facet_wrap(~ Type, scales = "free") 
scatterplot
```

```{r fig.height=8, fig.width=11}
variables_to_plot <- c("hasBasement", "hasAC", "hasFireplace", "hasGarage", "stories", "view",  "quality", "buildingdis")
subset_varibales <- neighboreffect %>% select(all_of(variables_to_plot)) %>%  st_drop_geometry()

long_vars <- gather(subset_varibales)

plot1 <- ggplot(long_vars, aes(x = value)) +
  geom_bar() +
  facet_wrap(~ key, scales = "free", ncol = 4) +
  #coord_flip() +
  labs(title = "Distribution of Variables",
       x = "Value",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

variables_to_plot <- c("DIST_NAME")
subset_varibales <- neighboreffect %>% select(all_of(variables_to_plot)) %>%  st_drop_geometry()

long_vars <- gather(subset_varibales)

plot2 <- ggplot(long_vars, aes(x = value)) +
  geom_bar() +
  facet_wrap(~ key, scales = "free") +
  #coord_flip() +
  labs(title = "Distribution of Variables",
       x = "Value",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

(plot1 | plot2) + plot_layout(widths = c(2, 1.5))

```


```{r}
neighboreffect <- neighboreffect %>% 
  mutate(sale_class = cut(sale_price, breaks = c(0, 250000, 500000, 750000, 1000000, max(neighboreffect$sale_price, na.rm=TRUE))))
  
ggplot()+
    geom_sf(data=dst, fill='grey80',color='transparent')+
    geom_sf(data=neighboreffect, size=0.75,aes(colour = q5(sale_class)))+
    geom_sf(data=dst,fill='transparent',color='black')+
    scale_color_manual(values = palette5,
                    name = "Sales Price (USD)",
                    na.value = 'grey80',
                    labels = c('$0-$250k', '$250k-$500k', '$500k-$750k', '$750k-$1m', '$1m+'))
```

```{r}
ggplot()+
  geom_sf(data=dst,fill='grey80',color='transparent')+
  geom_sf(data=neighboreffect,aes(colour = (crimes.Buffer)),size=0.24)+
 scale_color_continuous(low = "#FAF9F6", high = "red", name= "Crime Buffer") + 
  geom_sf(data=dst,fill='transparent',color='black')
```

```{r}

ggplot()+
  geom_sf(data=dst,fill='grey80',color='transparent')+
  geom_sf(data=neighboreffect,aes(colour = meanMinor),size=0.5)+
  scale_color_viridis(name = "Minority")+
  geom_sf(data=dst,fill='transparent',color='black')
```

```{r}
ggplot()+
  geom_sf(data=dst,fill='grey80',color='transparent')+
  geom_sf(data=neighboreffect,aes(colour = buildingdis),size=0.5)+
  scale_color_brewer(palette = "Set1", name = "Building Type")+
  geom_sf(data=dst,fill='transparent',color='black')
```



```{r}
ggplot()+
  geom_sf(data=dst,fill='grey80',color='transparent')+
  geom_sf(data=tr_neigh.test,aes(colour = SalePrice.Error),size=0.5)+
  scale_color_continuous(type = "viridis")

```


```{r}

PredictAllVal <- tr_neigh %>% 
  mutate(prediction = predict(reg.train, tr_neigh)) %>% 
  mutate(prediction_class = cut(prediction, breaks = c(0, 250000, 500000, 750000, 1000000, max(PredictAllVal$prediction, na.rm=TRUE))))

ggplot()+
    geom_sf(data=dst, fill='grey80',color='transparent')+
    geom_sf(data=PredictAllVal, size=0.75,aes(colour = q5(prediction_class)))+
    geom_sf(data=dst,fill='transparent',color='black')+
    scale_color_manual(values = palette5,
                    name = "Sales Price (USD)",
                    na.value = 'grey80',
                    labels = c('$0-$250k', '$250k-$500k', '$500k-$750k', '$750k-$1m', '$1m+'))

```


```{r}
ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = majority)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
    labs(title = "Race Context") +
    mapTheme() + theme(legend.position="bottom")
```



```{r}
st_join(tr_neigh.test, tracts20) %>% 
  filter(!is.na(majority)) %>%
  group_by(majority) %>%
  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(majority, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood income context") %>% 
  kable_styling()
```


```{r}
Phily<- st_read("https://raw.githubusercontent.com/emilyzhou112/MUSA5080-Philly-ML/main/data/neighborhood.geojson") %>% st_transform('ESRI:102728')

to_plot <- st_intersection(tr_neigh.test, Phily %>% dplyr::select("NAME")) %>% 
  st_drop_geometry() %>% 
  group_by(NAME) %>%
  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>% 
  left_join(Phily) %>% 
  st_sf()


  
to_plot %>%
  filter(NAME != "KENSINGTON") %>% 
  ggplot() + 
      geom_sf(aes(fill = mean.MAPE)) +
      scale_fill_viridis()


```


```{r}
tr_neigh.testPhilly <- st_join(tr_neigh.test, Phily %>% select(NAME)) %>% 
  group_by(NAME) %>%
  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>% 
  mutate(st_join(tr_neigh.test, Phily %>% select(NAME)) %>% group_by(NAME) %>%
  summarise(mean.Price = mean(sale_price, na.rm = T)))

tr_neigh.testPhilly %>% filter(NAME != "KENSINGTON") %>%
    ggplot(aes(mean.MAPE,mean.Price)) +
  geom_point() +
  plotTheme()


```


```{r, warning=FALSE}
seed_values <- 100:500

results <- numeric(length(seed_values))  

for (i in 1:length(seed_values)) {
  set.seed(seed_values[i])  
  inTrain <- createDataPartition(
    y = paste(neighboreffect$DIST_NAME, neighboreffect$hasBasement, neighboreffect$hasAC, neighboreffect$quality, neighboreffect$buildingdis, neighboreffect$hasFireplace, neighboreffect$hasGarage, neighboreffect$stories, neighboreffect$view), 
    p = .60, list = FALSE)
  
  tr_neigh.training <- neighboreffect[inTrain,] 
  tr_neigh.test <- neighboreffect[-inTrain,]  
  
  reg.train <- lm(sale_price ~ ., data = tr_neigh.training %>% st_drop_geometry() %>% 
                     dplyr::select(sale_price, Age, numRooms, hasBasement, hasAC, quality, buildingdis, 
                                   hasFireplace, hasGarage, stories, logarea, view, DIST_NAME, crimes.Buffer, totalstops, hospitals_nn1, shops_nn3, school_buffer, meanMinor))
  
  
  
  tr_neigh.test <- 
    tr_neigh.test %>% 
    mutate(SalePrice.Predict = predict(reg.train, tr_neigh.test),
           SalePrice.Error = SalePrice.Predict - sale_price,
           SalePrice.AbsError = abs(SalePrice.Predict - sale_price),
           SalePrice.APE = (abs(SalePrice.Predict - sale_price)) / SalePrice.Predict)
  
  results[i] <- mean(tr_neigh.test$SalePrice.APE, na.rm = TRUE) 
}

results
```



`

```{r}
test <- st_join(PredictAllVal, Phily) %>% 
  filter(is.na(prediction))

```

